---
title: "Multiple-Discrete Choice Extreme Value Model Estimation and Simulation in R: The rmdcev Package"
author:
  name: Patrick Lloyd-Smith
  affiliation: University of Saskatchewan
date: April 2019  #"`r format(Sys.time(), '%d %B %Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Multiple-Discrete Choice Extreme Value Model Estimation and Simulation in R: The rmdcev Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
#  html_document:
#    theme: flatly
#    highlight: haddock
#    toc: yes
#    toc_depth: 4
#    toc_float: yes
#    keep_md: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, dpi=300)
library(rmdcev)
```

This document introduces the package **rmdcev** in R for estimation and simulation of multiple-discrete choice extreme value models with individual heterogeneity. as well as subsequent demand and welfare simulation.

The models supported by rmdcev are multiple-discrete choice extreme value, the latent class, the mixed- multiple-discrete choice extreme value
The models are estimated using either penalized maximum likelihood estimator or hierarchal Bayes.
Demand and welfare simulations can
This article describes and demonstrates with real and simulated datasets all the functionalities of rmdcev.

 for cross-sectional and panel (longitudinal). The package also simulates demand and welfare implications.
The purpose of this paper is to describe the model

Keywords: multiple-discrete choice extreme value, Kuhn-Tucker, latent class, random parameters, demand, welfare, preference heterogeneity, R.

## Introduction

Individual choice contexts are often characterized by both extensive (i.e. what alternative to choose) and intensive (i.e. how much of an alternative to consume) margins. These multiple discrete-continuous (MDC) choice situations are pervasive, arising in transportation, marketing, health, and decisions regarding environmental resources.
Kuhn-Tucker (KT) consumer demand models are often employed to analyze these MDC situations and substantial progress has been made on improving the econometric modeling structures. There is currently no available software package that

In addition to **rmdcev**, the **Apollo** package from the Leeds Choice Modeling Centre provides a flexible interface to estimating MDCEV models and simulating demand. The main differences is that **rmdcev** 1) provides welfare simulation, 2) also implements the Kuhn-Tucker Linear Expenditure System utility specification, and 3) uses Stan software and NUTs sampling.


One reason cited for the lack of widespread use of these KT models is that applying these models for welfare analysis is not straightforward \citep{von_haefen_kuhn-tucker_2005, bhat_multiple_2014}. This issue is especially relevant in applying these models to studying decisions regarding environmental resources where producing welfare estimates is often the main purpose of the research.

I present a brief example below showing

## Models

### Conceptual framework

Each individual $i$ maximizes utility through the choice of the numeraire good ($\x_1$) and the non-numeraire alternatives ($x_k$) subject to a monetary budget constraint. We assume there is a numeraire good (i.e. essential Hicksian composite good) which is always consumed and has a price of one. The individual's maximization problem is

\begin{equation}
\max_{x_k, x_1} U(x_k, x_1) \; \;  \; \; s.t. \; \; y = \sum\limits^K_{k=2}p_k x_k + x_1,x_k \geq 0, k = 2,...,K  
\end{equation}

\noindent
where $x_k$ is the consumption level for alternative $k$, $x_1$ is consumption of the numeraire, $y$ is annual income, and $p_k$ is the unit price of alternative $k$.

The resulting first-order KT conditions that implicitly define the solution to the optimal consumption bundles of $x_k$ and $x_1$ are

\begin{eqnarray}
 \frac{U_{x_k}}{U_{x_1}} &\leq p_k,\; \; k = 1,....K,  \\
  x_k\left[\frac{U_{x_k}}{U_{x_1}} - p_k \right] &= 0,\; \; k = 1,....K.
\label{ktconditions}
\end{eqnarray}

For alternatives with positive consumption levels, the marginal rate of substitution between these alternatives and the numeraire good is equal to the price of the alternative. For unconsumed alternatives, the marginal rate of substitution between these alternatives and the numeraire good is less than the price of the alternatives.

These first-order conditions can be used to derive Hicksian demands and welfare measures. The Hicksian compensating surplus ($CS^H$) for a change in price and quality from baseline levels $p^0$ and $q^0$ to new `policy' levels $p^1$ and $q^1$ is defined implicitly using an indirect utility function

\begin{align}
V(p^0, q^0, y, \theta, \varepsilon) = V(p^1, q^1, y - CS^H, \theta, \varepsilon)
\label{welfare_indirect}
\end{align}

\noindent
or explicitly using an expenditure function

\begin{align}
CS^H = y - e(p^1, q^1, \bar{U}, \theta, \varepsilon)
\label{welfare}
\end{align}

\noindent
where $y$ is income, $\theta$ is the vector of structural parameters ($\psi_k, \alpha_k, \gamma_k$), $\varepsilon$ is a vector or matrix of unobserved heterogeneity, and $\bar{U} = V(p^0, q^0, y, \theta, \varepsilon)$.

## MDCEV

The **rmdcev** package implements the random utility specification as introduced by \cite{bhat2008multiple}. The utility function is specified as

\begin{equation}
\label{utilkt}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha_k}\psi_k \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{\psi_1}{\alpha_1}x_1^{\alpha_1}
\end{equation}

\noindent
where $x_k$ is the consumption level for alternative $k$, $x_1$ is consumption of the numeraire, $y$ is annual income, and $p_k$ is the unit price of alternative $k$.

where $\gamma_k, \psi_k > 0$ and $\alpha_k, \alpha_1 \leq 1$ for all $k$ are required for this function to be consistent with the properties of a utility function \citep{bhat2008multiple}. Bhat (2008) provides an overview of the parameter interpretation and in brief

- The $\psi_k$ parameters represent the marginal utility of consuming alternative $k$ at the point of zero consumption (i.e. baseline marginal utility).
- The $\gamma_k$ parameters are translation parameters that allow for corner solutions (i.e. zero consumption levels for alternatives) and also influence satiation. The lower the value of $\gamma_k$, the more satiation effect in consuming $x_k$.
- The $\alpha$ parameters control the rate of diminishing marginal utility of additional consumption. If $\alpha_k$ equal to one, then there is no satiation effects (i.e. constant marginal utility).

A multiplicative random element is introduced into the baseline marginal utility as

\begin{equation}
\psi_k=\psi(z_k,\varepsilon_k)= exp(\beta'z_k+\varepsilon_k)
\end{equation}

\noindent
where $\z_k$ is a set of variables that can include alternative-specific attributes and individual-specific characteristics, and $\varepsilon_k$ is an error term that allows for the utility function to be random over the population. We assume an extreme value distribution that is independently distributed across alternatives for $\varepsilon_k$ with an associated scale parameter of $\sigma$.

We specify the following parameterization of the utility function parameters

$\psi_k=exp(\beta_q Q_k + \beta_s S_i + \varepsilon_k)$,

$\gamma_k = exp(\gamma_k)$, and

$\alpha = 1 - exp(\alpha)$.

For identification, specify $\psi_1= e^{\varepsilon_1}$.

Weak complementarity, which is required for deriving unique welfare measures, is imposed in this specification by adding and subtracting one in the non-numeraire part of the utility function.


Bhat (2008) discusses the identification concerns regarding estimating separate $\gamma_k$ and $\alpha_k$ parameters for each non-numeraire alternative. There are three possible utility function specifications

1. $\alpha$-profle:

\begin{equation}
\label{utilkt_alpha}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{1}{\alpha_k}exp(\beta'z_k+\varepsilon_k) \left[ \left( x_k + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

2. $\gamma$-profle:

\begin{equation}
\label{utilkt_gamma}
U(x_k, x_1) = \sum_{k=2}^{K} \gamma_k exp(\beta'z_k+\varepsilon_k) \ln\left( \frac{x_k}{\gamma_k} + 1 \right) + \frac{exp(\varepsilon_1)}{\alpha_1}x_1^{\alpha_1}
\end{equation}

3. Hybrid-profile:

\begin{equation}
\label{utilkt_hybrid}
U(x_k, x_1) = \sum_{k=2}^{K} \frac{\gamma_k}{\alpha} exp(\beta'z_k+\varepsilon_k) \left[ \left( \frac{x_k}{\gamma_k} + 1 \right)^{\alpha_k} - 1 \right] + \frac{exp(\varepsilon_1)}{\alpha}x_1^{\alpha}
\end{equation}


The resulting model probability of the consumption pattern where $M$ goods are chosen can be expressed as \citep{bhat2008multiple}

\begin{equation}
P(x^{*}_1,x^{*}_2...x^{*}_M,0,...,0) = \frac{1}{\sigma^{M-1}} \left(\prod_{m=1}^M c_m \right)\left(\sum_{m=1}^M \frac{1}{c_j} \right) \left( \ \frac{\prod_{m=1}^M e^{V_m/\sigma}}{ \left( \sum_{k=1}^J e^{V_k/\sigma} \right)^M }\right)(M-1)!
\end{equation}

\noindent
where $\sigma$ is a scale parameter and $c_m = \frac{1-\alpha}{x_m+ \gamma_m}$. The $V$ expressions depend on what model specification is used:

1. $\alpha$-profle: $V_k = \beta' z_k + (\alpha_k-1)\ln\left( x_k + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

2. $\gamma$-profle: $V_k = \beta' z_k - \ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$ for $k \geq 2$, and $V_1 = (\alpha_1-1)\ln(x_1)$.

3. Hybrid-profile: $V_k = \beta' z_k + (\alpha-1)\ln\left( \frac{x_k}{\gamma_k} + 1 \right) - \ln \left(p_k\right)$, and $V_1 = (\alpha-1)\ln(x_1)$.

## Latent Class MDCEV

## Random parameters

## The rmdcev package

### Data format

The **rmdcev** pacakage accepts data in ``long" format (one row per available non-numeraire alternative). There is no row for the numeraire good. The following named columns are requires:

- **id**: The id variable for each individual
- **good**: The variable containing the good number
- **quant**: Consumption levels for each good
- **price**: Price levels for each good
- **inc**: Income level for each individual

Data must be arranged by id and then good.

```{r, data}
data(data_rec, package = "rmdcev")
data_rec
```

We can summarize the average consumption and price levels for each good as:

```{r, summary}
data_rec %>%
	group_by(good, good_name) %>%
	summarise(mean_quant = mean(quant),
			  mean_price = mean(price))
```



###	Formula interface

The $z_k$ variables can be specified using the **psi_formula** interface. This formula is based on the R package **Formula** (Zeileis and Crossiant, 2010).

```r
psi_formula = ~ z1 + z2 + z3
```

Note that the formula will automatically include a constant but a constant can be omitted if -1 is used in the formula.

### Estimating MDCEV

We estimate a MDCEV model using the **Recreation** data where we include acticity-specific constants in the $\psi$ parameter. We start with the maximum likelihood estimation by setting algorithm = "MLE" and using the gamma model specification where alpha is set to 0 by using model = "gamma0".

The basic syntax is the following:

```{r, create_dummies}
data_rec <- data_rec %>% 
  mutate(v = 1, yr = good_name) %>% 
  spread(yr, v, fill = 0) %>%
	arrange(id, good)
```

```{r, estimation_mdcev}
mdcev.fit <- FitMDCEV(psi_formula = ~ beach + birding + camping + cycling + fish + garden + golf +
					 hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl + motor_land + 
					 	motor_water + photo + ski_cross + ski_down -1,
							data = data_rec,
							model = "gamma0",
							algorithm = "MLE",
					  		print_iterations = FALSE)
```

There are four possible model options

- "les": Linear expenditure system with one estimated $\alpha_1$ and all non-numeraire $\alpha$ parameters equal to 1.
- "alpha": $\alpha$-profile with all $\gamma_k$ equal to 1.
- "gamma": $\gamma$-profile with a single estimated $\alpha$ (i.e. $\alpha_1 = \alpha_k = \alpha$.
- "gamma0": $\gamma$-profile with all  $\alpha$ equal to 1e-6.

```{r, summary_mdcev}
	SummaryMDCEV(mdcev.fit)
```


### Estimating MDCEV with HB

One benefit of using the Heirarchal Bayes routine is that we can take advantage of the postestimation commands in **rstan** and **shinystan**.

### Estimating Latent Class MDCEV

In this example, we estimate a LC model with two classes. To include variables in the membership equation we specify them in the **lc_formula** interface. The LC model is estimated as long as **n_classes** is set greater than 2.

```{r, estimation_mdcev_lc}
mdcev.lc <- FitMDCEV(psi_formula = ~ beach + birding + camping + cycling + fish + garden + golf +
					 hiking + hunt_birds + hunt_large + hunt_trap + hunt_waterfowl + motor_land + 
					 	motor_water + photo + ski_cross + ski_down -1,
            				  lc_formula = ~ university + ageindex + urban,
            					data = data_rec,
            				  n_classes = 2,
            					model = "gamma0",
            					algorithm = "MLE",
					  			print_iterations = FALSE)
```
We can interpret the beta_m parameters as...

```{r, summary_mdcev_lc}
	SummaryMDCEV(mdcev.lc)
```

### Estimating Random Parameters MDCEV

*too come*

## Rmdcev Demand and Welfare Simulation

The **rmdcev** package includes simulation functions for calculating forecasted demand and welfare measures. There are two steps to simulation. In the first step we draw simulated values for the unobserved heterogeneity term ($\varepsilon$) using Monte Carlo simulation techniques. The second step uses these draws, model parameters and the data to calculate Marhsallian or Hicksian demands. 

### Step 1: Simulating unobervered heterogeneity

Unconditional vs Conditional Error Draws

To address the first issue, Monte Carlo simulation techniques can be employed to draw simulated values of the unobserved heterogeneity ($\varepsilon$) and then a measure of the central tendency of $CS^H$ such as its expectation can be computed. The main implication of using these Monte Carlo techniques is that now $CS^H$ needs to be computed for each simulated value of $\varepsilon$ which can be burdensome if the approach used to calculate $CS^H$ is slow. This implication has partially motivated the use of conditional draws of $\varepsilon$ which avoids the need to calculate consumption patterns in the baseline state as well as simulate the entire distribution of unobserved heterogeneity. The conditional approach to welfare measurement draws $\varepsilon$ such that the model perfectly predicts the observed consumption patterns in the baseline state \citep{von_haefen_kuhn-tucker_2005}.

For unconditional errors, 

Truncated $\varepsilon_{k} = -log(-log(uniform(0,1)))) * \sigma$

where uniform(0,1) is a uniform random draw

2. Conditional error draw

For conditional error draws, the simulation depends on whether an alternative is consumed or not. 
If $x_k>0$, set  $\varepsilon_k = (V_1 - V_k)/ \sigma$ where $V_1$ and $V_k$ depend on the model specification.

If $x_k=0$, $\varepsilon_k < (V_1 - V_k)/ \sigma$ and we can simulate $\varepsilon_k$ from the truncated type I extreme value distribution such that 

$\varepsilon_k = -log(-log(uniform(0, 1) * exp(-exp(v1 - vk)))) * \sigma$

In both cases, we normalize $\varepsilon_1=0$. 


### Step 2: Calculating Demand and Welfare measures

\cite{vonhaefen_empirical_2007} builds on \cite{von_haefen_estimation_2004} using a more efficient numerical approach by making use of the explicit definition of $CS^H$ shown in Equation (\ref{welfare}). The approach exploits the additively separable utility function structure and replaces the two level numerical bisection routines in \cite{von_haefen_estimation_2004} with a single numerical bisection routine. I fully describe the steps of the algorithm below because I use this approach as a benchmark to compare the computational performance of the new approach introduced in this paper. For the rest of the paper, I refer to this approach as the numerical bisection algorithm.

#### Marshallian Demand

Pinjari and Bhat (2011)


#### Welfare Analysis

Lloyd-Smith (2017)

## Modelling notes



## Conclusions

The **rmdcev** package implements the MDCEV . In this paper, we have demonstrated the use of the pacakage to estimate several model specifications and to derive welfare.

## Appendix



### Specific steps in algorithm for Hybrid-profile utility functions

**Step 0**: Assume that only the numeraire alternative is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire alternative is in the first place. Go to step 2.

**Step 2**: Compute the value of $\lambda^E$ using the following equation:

\begin{align}
\label{lambdaE}
\frac{1}{\lambda^E} = \left[ \frac{\alpha \bar{U} + \sum_{m=2}^{M} \gamma_m \psi_m} {\sum_{m=2}^{M} \gamma_m \psi_m \left( \frac{p_m}{\psi_m} \right)^\frac{\alpha}{\alpha-1} + \psi_1 \left(\frac{p_1}{\psi_1} \right)^\frac{\alpha}{\alpha-1}} \right] ^\frac{\alpha-1}{\alpha}.
\end{align}

Go to step 3.

**Step 3**: If $\frac{1}{\lambda^E} > \frac{\psi_{M+1}}{p_{M+1}}$, go to step 4. Else if $\frac{1}{\lambda^E} < \frac{\psi_{M+1}}{p_{M+1}}$, set $M = M + 1$. If $M < K$, go back to step 2. If $M = K$, go to step 4.

**Step 4**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using the following equations

\begin{align}
\begin{split}
\label{foc13}
x_1 &=   \left( \frac{p_1}{\lambda^E \psi_1} \right)^\frac{1}{\alpha_1-1}\text{, and} \\
x_m &=   \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{1}{\alpha_m-1}-1 \right]\gamma_m, \; \; \text{if} \; \; x_m > 0.
\end{split}
\end{align}

Set the remaining alternative consumption levels to zero and stop.

### Specific steps in algorithm for general utility functions:

In the more general case of a utility function with different $\alpha_k$ parameters for each alternative, I modify the algorithm in Section 3.2. In this context, there is no closed-form expressions for $\lambda^E$ and I need to conduct a numerical bisection routine. Let $\hat{\lambda^E}$ and $\hat{U}$ be estimates of $\lambda^E$ and $U$ and let $tol_{\lambda}$ and $tol_{U}$ be the tolerance levels for estimating $\lambda^E$ and $U$ that can be arbitrarily small.

**Step 0**: Assume that only the numeraire is chosen and let the number of chosen alternatives equal one (M=1).

**Step 1**: Using the data, model parameters, and either conditional or unconditional simulated error term draws, calculate the price-normalized baseline utility values ($\psi_k/p_k$) for all alternatives. Sort the $K$ alternatives in the descending order of their price-normalized baseline utility values. Note that the numeraire is in the first place. Go to step 2.

**Step 2**: Let $\frac{1}{\hat{\lambda^E}} = \frac{\psi_{M+1}}{p_{M+1}}$ and substitute $\hat{\lambda^E}$ into the following quation to obtain an estimate of $\hat{U}$.

\begin{align}
\bar{U}=\sum_{M=2}^{M} \frac{\gamma_m}{\alpha_m}\psi_m \left[ \left( \frac{p_m}{\lambda^E \psi_m} \right)^\frac{\alpha_m}{\alpha_m-1} - 1 \right] + \frac{\psi_1}{\alpha_1}\left(\frac{p_1}{\lambda^E \psi_1} \right)^\frac{\alpha_1}{\alpha_1-1}.
\label{util_algo}
\end{align}

**Step 3**: If $\hat{U} < \bar{U}$, go to step 4. Else, if $\hat{U} \geq \bar{U}$, set $\frac{1}{\lambda_l^E}= \frac{\psi_{M+1}}{p_{M+1}}$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{M}}{p_{M}}$. Go to step 5.

**Step 4**: Set $M=M+1$. If $M<K$, go to step 2. Else if $M=K$, set $\frac{1}{\lambda_l^E}= 0$ and $\frac{1}{\lambda_u^E}= \frac{\psi_{K}}{p_{K}}$. Go to step 5.

**Step 5**: Let $\hat{\lambda^E}= (\lambda_l^E+\lambda_u^E)/2$ and substitute $\hat{\lambda^E}$ into Equation (\ref{util_algo}) to obtain an estimate of $\hat{U}$. Go to step 6.

**Step 6**: If $|\lambda_l^E-\lambda_u^E| \leq \; tol_{\lambda}$ or $|\hat{U}-\bar{U}| \leq \; tol_{U}$, go to step 7. Else if $\hat{U}<\bar{U}$, update $\lambda^E_u= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5. Else if $\hat{U}>\bar{U}$, update $\lambda^E_l= (\lambda_l^E+\lambda_u^E)/2$ and go to step 5.

**Step 7**: Compute the optimal Hicksian consumption levels for the first $I$ alternatives in the above descending order using Equation (\ref{foc13}). Set the remaining alternative consumption levels to zero and stop.
